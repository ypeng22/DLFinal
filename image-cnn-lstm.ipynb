{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "subjects = ['S01', 'S02', 'S03', 'S04', 'S05','S06', 'S07', 'S08', 'S09', 'S10', 'S11', 'S12']\n",
    "actions = ['A01', 'A02', 'A03', 'A04', 'A05','A06', 'A07', 'A08', 'A09', 'A10', 'A11']\n",
    "reps = ['R01', 'R02', 'R03', 'R04', 'R05']\n",
    "\n",
    "class BerkeleyMHAD(Dataset):\n",
    "\n",
    "    def __init__(self, vid_names, root_dir, classes, transform=None):\n",
    "        self.vid_names = vid_names # list of file names for videos (ex. S01_A01_R01)\n",
    "        self.root_dir = root_dir # directory where videos are stored\n",
    "        self.transform = transform\n",
    "        self.classes = classes\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.vid_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        path = os.path.join(self.root_dir, self.vid_names[idx])\n",
    "        x = np.load(path)['x']\n",
    "        label = self.classes.index(np.load(path)['y']) #my goals are beyond your understanding\n",
    "        sample = {'x': x, 'y': label}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "    \n",
    "class cnn_lstm(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super(cnn_lstm, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 3, 5,)\n",
    "        self.conv2 = nn.Conv2d(3, 3, 5)\n",
    "        self.pool1 = nn.MaxPool2d(3)\n",
    "        self.n_hidden = 100\n",
    "        self.n_layers = 1\n",
    "        self.l_lstm = torch.nn.LSTM(input_size = 1296, \n",
    "                                 hidden_size = self.n_hidden,\n",
    "                                 num_layers = self.n_layers, \n",
    "                                 batch_first = True)\n",
    "        self.fc1 = nn.Linear(100, 50)\n",
    "        self.fc2 = nn.Linear(50, classes)\n",
    "        self.relu = nn.LeakyReLU(.1)\n",
    "        self.soft = nn.Softmax(dim = 0)\n",
    "    def forward(self, x):\n",
    "        batch = x.shape[0]\n",
    "        #intialize lstm hidden state\n",
    "        hidden_state = torch.zeros(self.n_layers, 1, self.n_hidden).to(dev)\n",
    "        cell_state = torch.zeros(self.n_layers, 1, self.n_hidden).to(dev)\n",
    "        self.hidden = (hidden_state, cell_state)\n",
    "        \n",
    "        x = self.pool1(self.relu(self.conv1(x)))\n",
    "        x = self.pool1(self.relu(self.conv2(x)))\n",
    "        x = x.reshape(batch, -1).unsqueeze(0)\n",
    "        #print(x.shape)\n",
    "        lstm_out, _ = self.l_lstm(x, self.hidden) #lstm_out shape is batch_size, seq len, hidden state\n",
    "        #print(lstm_out.shape)\n",
    "        lstm_out = lstm_out[:,-1,:]\n",
    "        #print(lstm_out.shape)\n",
    "        lstm_out = self.relu(self.fc1(lstm_out.squeeze()))\n",
    "        lstm_out = self.relu(self.fc2(lstm_out))\n",
    "        lstm_out = self.soft(lstm_out)\n",
    "        return lstm_out\n",
    "    \n",
    "def check(i):\n",
    "    #insert more i.find terms for each action\n",
    "    return i.find('A01') != -1 or i.find('A07') != -1\n",
    "vid_names = [i for i in next(os.walk('./rgb_video_data'))[2] if check(i)]\n",
    "train_vid_names = [i for i in vid_names if i.find('S09') == -1 and i.find('S10') == -1 and i.find('S11') == -1 and i.find('S12') == -1]\n",
    "valid_vid_names = [i for i in vid_names if i.find('S09') != -1 ]\n",
    "test_vid_names = [i for i in vid_names if i.find('S10') != -1 or i.find('S11') != -1 or i.find('S12') != -1]\n",
    "\n",
    "#data shape is (num_pics, height, width, channel)\n",
    "train_dataset = BerkeleyMHAD(train_vid_names, './rgb_video_data', classes = [0, 6])\n",
    "valid_dataset = BerkeleyMHAD(valid_vid_names, './rgb_video_data', classes = [0, 6])\n",
    "test_dataset = BerkeleyMHAD(test_vid_names, './rgb_video_data', classes = [0, 6])\n",
    "plt.imshow(train_dataset[0]['x'][0])\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#change 2 to number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn_lstm(2).to(dev)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epoch = 1\n",
    "#train\n",
    "\n",
    "tguess = []\n",
    "tanswers = []\n",
    "tcorrect = 0\n",
    "ttotal = 0\n",
    "for t in range(epoch):\n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "    tguess = []\n",
    "    tanswers = []\n",
    "    tcorrect = 0\n",
    "    ttotal = 0\n",
    "    for i in range(len(train_dataset)):\n",
    "        data = train_dataset[i]\n",
    "        inpt = torch.tensor(data['x'], dtype=torch.float).permute(0, 3, 1, 2).to(dev)\n",
    "        label = torch.tensor(data['y']).unsqueeze(0).to(dev)\n",
    "        output = model(inpt).unsqueeze(0)\n",
    "        loss = criterion(output, label) #.view(-1)\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        if torch.argmax(output.squeeze()) == label:\n",
    "            tcorrect += 1\n",
    "        ttotal += 1\n",
    "        tanswers.append(label.item())\n",
    "        tguess.append(output[0][1].item())\n",
    "        \n",
    "    torch.cuda.empty_cache()   \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(valid_dataset)):\n",
    "            data = valid_dataset[i]\n",
    "            inpt = torch.tensor(data['x'], dtype=torch.float).permute(0, 3, 1, 2).to(dev)\n",
    "            label = torch.tensor(data['y']).unsqueeze(0).to(dev)\n",
    "            output = model(inpt).unsqueeze(0)\n",
    "            loss = criterion(output, label)\n",
    "            valid_loss += loss.item()\n",
    "    print(\"epoch:\", valid_loss / len(valid_dataset), train_loss / len(train_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess = []\n",
    "answers = []\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_dataset)):\n",
    "        data = test_dataset[i]\n",
    "        inpt = torch.tensor(data['x'], dtype=torch.float).permute(0, 3, 1, 2).to(dev)\n",
    "        label = torch.tensor(data['y']).to(dev)\n",
    "        output2 = model(inpt)\n",
    "        if torch.argmax(output2.squeeze()) == label:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        answers.append(label.item())\n",
    "        guess.append(output2[1].item())\n",
    "#guess = torch.argmax(guess.squeeze(), dim=1)\n",
    "#guess = np.array(guess).squeeze()\n",
    "print(correct / total)\n",
    "#print('CNN AUC: %.4f' % roc_auc_score(testlabel, guess), ' AUPRC: %.4f' % average_precision_score(testlabel, guess))\n",
    "torch.save(model, 'cnn_lstm.torch')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
