{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_proj.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2lUN0niNPQq"
      },
      "source": [
        "# Training a LSTM on Berkeley MHAD data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZyv_9X0kb6s"
      },
      "source": [
        "!pip install plantcv\n",
        "!pip install c3d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gnveOQLzZs-"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import c3d\n",
        "import cv2\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "from plantcv import plantcv as pcv\n",
        "from scipy import ndimage\n",
        "import torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCAC2zBMNOjE",
        "outputId": "ee033a8b-e055-4dce-e948-35a9bd67088e"
      },
      "source": [
        "## Mount Google Drive Data (If using Google Colaboratory)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "except:\n",
        "    print(\"Mounting Failed.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prEI4BySN1tM"
      },
      "source": [
        "data_dir = \"/content/gdrive/MyDrive/BerkeleyMHAD/\"\n",
        "subjects = ['S01', 'S02', 'S03', 'S04', 'S05','S06', 'S07', 'S08', 'S09', 'S10', 'S11', 'S12']\n",
        "actions = ['A01', 'A02', 'A03', 'A04', 'A05','A06', 'A07', 'A08', 'A09', 'A10', 'A11']\n",
        "reps = ['R01', 'R02', 'R03', 'R04', 'R05']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVxw1YsKzHUp"
      },
      "source": [
        "############### Safe to delete this code now. See dataloader below ###################\n",
        "\n",
        "def c3d2array(loc: str):\n",
        "    \"\"\"\n",
        "    Takes in the file location of the c3d file as a string and returns a \n",
        "    numpy array w/ the sensor data\n",
        "    Array Shape: Num_frames x 43 x 3 \n",
        "      43 corresponds to the number of nodes on the person\n",
        "      3 corresponds to spatial coordinates of the nodes\n",
        "    \"\"\"\n",
        "    point_series = []\n",
        "    reader = c3d.Reader(open(loc, 'rb'))\n",
        "    for i, points, analog in reader.read_frames():     \n",
        "        if i % 22 == 0: ## Set Frame Rate to approximately 22 Hz instead of 480 Hz\n",
        "            point_series.append(points[:, 0:3])\n",
        "    point_series = np.array(point_series)\n",
        "    return point_series\n",
        "\n",
        "## Some funny data visualization L0L\n",
        "## the x-coordinate represents the width of the person (shoulder to shouler)\n",
        "## the y-coordinate represents the depth of the person\n",
        "## the z-coordinate represents the height of the person   \n",
        "## There is a point at (0, 0, 0) for all the samples for callibration purposes    \n",
        "test = c3d2array(data_dir + '/Mocap/OpticalData/moc_s01_a02_r01.c3d')\n",
        "frame = 30\n",
        "xs, ys, zs = test[frame, :, 0], test[frame, :, 1], test[frame, :, 2]\n",
        "plt.scatter(xs, zs)\n",
        "plt.axis('scaled')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSGM-xw4cj4_"
      },
      "source": [
        "################ Dataloader for Berkeley Mocap Optical Data #################\n",
        "\n",
        "def c3d2array(loc: str, frame_rate):\n",
        "    \"\"\"\n",
        "    Takes in the file location of the c3d file as a string and returns a \n",
        "    numpy array w/ the sensor data\n",
        "    Array Shape: Num_frames x 43 x 3 \n",
        "      43 corresponds to the number of nodes on the person\n",
        "      3 corresponds to spatial coordinates of the nodes\n",
        "    \"\"\"\n",
        "    point_series = []\n",
        "    reader = c3d.Reader(open(loc, 'rb'))\n",
        "    for i, points, analog in reader.read_frames():     \n",
        "        if i % frame_rate == 0: ## Set Frame Rate to approximately 22 Hz instead of 480 Hz\n",
        "            point_series.append(points[:, 0:3])\n",
        "    point_series = np.array(point_series)\n",
        "    return point_series\n",
        "\n",
        "class BerkeleyMocapOpticalDataset(Dataset):\n",
        "    \"\"\"Berkeley Mocap Optical Dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, frame_rate, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (string): Directory with all the data\n",
        "            frame_rate (integer): In Hz \n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.list_c3d = [file for file in os.listdir(root_dir) if (os.path.isfile(os.path.join(root_dir, file)) and file[-1] != 't' ) ] #list of all the c3d file names\n",
        "        self.frame_rate = frame_rate\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.list_c3d)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        c3d_file_location = os.path.join(self.root_dir,\n",
        "                                self.list_c3d[idx])\n",
        "        sample = c3d2array(c3d_file_location, self.frame_rate)\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "        return sample\n",
        "\n",
        "\n",
        "############### Compute Mean and SD across the dataset #############\n",
        "transform = None\n",
        "root_dir = data_dir + 'Mocap/OpticalData'\n",
        "frame_rate = 1\n",
        "\n",
        "dataloader = BerkeleyMocapOpticalDataset(root_dir, 1)\n",
        "x_list = []\n",
        "y_list = []\n",
        "z_list = []\n",
        "\n",
        "for sample in dataloader:\n",
        "  x_list.append(np.ndarray.flatten(sample[:,:,0]))\n",
        "  y_list.append(np.ndarray.flatten(sample[:,:,1]))\n",
        "  z_list.append(np.ndarray.flatten(sample[:,:,2]))\n",
        "\n",
        "x_list = np.concatenate(np.array(x_list))\n",
        "y_list = np.concatenate(np.array(y_list))\n",
        "z_list = np.concatenate(np.array(z_list))\n",
        "x_mean = np.mean(x_list)\n",
        "x_sd = np.std(x_list)\n",
        "y_mean = np.mean(y_list)\n",
        "y_sd = np.std(y_list)\n",
        "z_mean = np.mean(z_list)\n",
        "z_sd = np.std(z_list)\n",
        "\n",
        "############### Define a transform with mean, std, and tensor ############\n",
        "transform = torchvision.transforms.Compose([\n",
        "  torchvision.transforms.ToTensor(),\n",
        "  torchvision.transforms.Normalize((x_mean, y_mean, z_mean), (x_sd, y_sd, z_sd)),\n",
        "])\n",
        "\n",
        "\n",
        "############# Final Dataloader ####################\n",
        "dataloader = BerkeleyMocapOpticalDataset(root_dir, 22, transform=transform)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ehz48DvAcqVk"
      },
      "source": [
        "############ Test Dataloader ######################\n",
        "i = 3\n",
        "for sample in dataloader:\n",
        "  if i == 0:\n",
        "    break\n",
        "  i = i - 1\n",
        "  frame = 1\n",
        "  xs, ys, zs = sample[0, frame, :], sample[1, frame, :], sample[2, frame, :]\n",
        "  plt.figure()\n",
        "  plt.scatter(xs, zs)\n",
        "  plt.axis('scaled')\n",
        "  xs, ys, zs = sample[0, frame+10, :], sample[1, frame+10, :], sample[2, frame+10, :]\n",
        "  plt.scatter(xs, zs)\n",
        "  plt.axis('scaled')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4kbS8X13n6u"
      },
      "source": [
        "X = []\n",
        "subjects = ['S03', 'S04', 'S05','S06', 'S07', 'S08', 'S09', 'S10', 'S11', 'S12']\n",
        "actions = ['A03', 'A04', 'A05','A06', 'A07', 'A08', 'A09', 'A10', 'A11']\n",
        "for i, action in enumerate(actions):\n",
        "    for subject in subjects:\n",
        "        for repeat in reps:\n",
        "            if subject == 'S04' and action == 'A04' and repeat == 'R05':\n",
        "              continue\n",
        "            if subject == 'S01' or subject == 'S02':\n",
        "              continue\n",
        "            if subject == 'S03' and action == 'A01':\n",
        "              continue\n",
        "            if subject == 'S03' and action == 'A02':\n",
        "              continue\n",
        "            image_path = data_dir + 'Camera/Cluster01/Cam01/' + str(subject) + '/' + str(action) + '/' + str(repeat) + '/'\n",
        "            dirs = os.listdir(image_path)\n",
        "            sample = []\n",
        "            for dir in dirs:\n",
        "                sample.append(ndimage.zoom(pcv.readbayer(image_path + dir, bayerpattern='GR')[0][:,120:480], [1/2, 1/2, 1]))\n",
        "            #X.append(np.array(sample))\n",
        "            np.savez(\"/content/gdrive/My Drive/rgb_video_data/\" + str(subject) + '_' + str(action) + '_' + str(repeat), x=np.array(sample), y=i)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83rvSHOc43q-"
      },
      "source": [
        "class BerkeleyMHAD(Dataset):\n",
        "\n",
        "    def __init__(self, vid_names, root_dir, transform=None):\n",
        "        self.vid_names = vid_names # list of file names for videos (ex. S01_A01_R01)\n",
        "        self.root_dir = root_dir # directory where videos are stored\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.vid_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        path = os.path.join(self.root_dir, self.vid_names[idx])\n",
        "        x = np.load(path)['x']\n",
        "        label = np.load(path)['y']\n",
        "        sample = {'x': x, 'y': label}\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBsuvtMAOLgg"
      },
      "source": [
        "data_dir = \"/content/gdrive/My Drive/dl_proj_data\"\n",
        "mhad_dataset = BerkeleyMHAD(vid_names=os.listdir(data_dir), root_dir=data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1M2YxAKWGFI",
        "outputId": "58804c0b-1f53-4d71-d9c4-0de7528c8d7e"
      },
      "source": [
        "sample = mhad_dataset[2]\n",
        "sample"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': array([[[ 17,  17,  17, ...,  54,  48,  55],\n",
              "         [ 16,  20,  20, ...,  51,  38,  48],\n",
              "         [ 25,  23,  23, ...,  55,  52,  50],\n",
              "         ...,\n",
              "         [ 35, 103,  32, ...,  67,  64, 115],\n",
              "         [162, 148, 111, ...,  63,  96, 118],\n",
              "         [ 33, 160,  37, ...,  66,  61, 114]],\n",
              " \n",
              "        [[ 16,  16,  17, ...,  54,  51,  53],\n",
              "         [ 16,  19,  18, ...,  49,  39,  51],\n",
              "         [ 23,  24,  25, ...,  54,  51,  53],\n",
              "         ...,\n",
              "         [ 38, 100,  28, ...,  66,  62, 112],\n",
              "         [157, 149, 109, ...,  63,  93, 121],\n",
              "         [ 33, 163,  36, ...,  64,  58, 112]],\n",
              " \n",
              "        [[ 16,  17,  17, ...,  53,  51,  53],\n",
              "         [ 17,  20,  20, ...,  50,  38,  50],\n",
              "         [ 23,  25,  23, ...,  55,  52,  55],\n",
              "         ...,\n",
              "         [ 36,  97,  31, ...,  69,  60, 115],\n",
              "         [157, 149, 110, ...,  65,  93, 121],\n",
              "         [ 36, 156,  37, ...,  66,  56, 114]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 15,  17,  17, ...,  52,  50,  53],\n",
              "         [ 17,  20,  17, ...,  50,  39,  49],\n",
              "         [ 24,  24,  23, ...,  54,  52,  52],\n",
              "         ...,\n",
              "         [ 34,  99,  29, ...,  68,  64, 113],\n",
              "         [161, 152, 110, ...,  64,  96, 119],\n",
              "         [ 33, 159,  36, ...,  66,  58, 113]],\n",
              " \n",
              "        [[ 15,  17,  17, ...,  51,  52,  52],\n",
              "         [ 16,  20,  18, ...,  49,  36,  48],\n",
              "         [ 25,  25,  23, ...,  53,  52,  52],\n",
              "         ...,\n",
              "         [ 34, 104,  29, ...,  68,  59, 115],\n",
              "         [159, 152, 112, ...,  64,  92, 120],\n",
              "         [ 35, 163,  39, ...,  65,  56, 112]],\n",
              " \n",
              "        [[ 17,  17,  17, ...,  53,  51,  52],\n",
              "         [ 16,  19,  18, ...,  51,  39,  50],\n",
              "         [ 25,  25,  23, ...,  52,  50,  52],\n",
              "         ...,\n",
              "         [ 37, 104,  29, ...,  68,  59, 114],\n",
              "         [164, 153, 111, ...,  66,  94, 120],\n",
              "         [ 35, 160,  36, ...,  67,  60, 111]]], dtype=uint8), 'y': array(0)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    }
  ]
}