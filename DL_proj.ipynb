{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of DL_proj.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ypeng22/DLFinal/blob/main/DL_proj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEk7c_MDbSgX"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZyv_9X0kb6s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63004cd3-ce8e-4f67-bcf1-f99eb8ddd453"
      },
      "source": [
        "!pip install plantcv\n",
        "!pip install c3d"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting plantcv\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/0c/f630364077ef27282906f46e56c670d1e9abd5d6cca0de67bc91388f0a14/plantcv-3.12.0-py3-none-any.whl (222kB)\n",
            "\r\u001b[K     |█▌                              | 10kB 15.5MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 14.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 30kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 40kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 51kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 61kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 71kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 81kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 92kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 102kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 112kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 122kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 133kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 143kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 153kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 163kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 174kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 184kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 194kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 204kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 215kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 225kB 8.2MB/s \n",
            "\u001b[?25hCollecting dask-jobqueue\n",
            "  Downloading https://files.pythonhosted.org/packages/22/4a/bf4ea9c12c825d0926899d9c08d1abc009ac0779c6b2476aa419a02de719/dask_jobqueue-0.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from plantcv) (1.1.5)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from plantcv) (0.16.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from plantcv) (0.22.2.post1)\n",
            "Requirement already satisfied: plotnine in /usr/local/lib/python3.7/dist-packages (from plantcv) (0.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from plantcv) (1.4.1)\n",
            "Collecting opencv-python<4,>=3.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/a2/e081e1d8831ce4dc1629ba36f1e010a56225b00532e2edad76e1bc7faef9/opencv_python-3.4.13.47-cp37-cp37m-manylinux2014_x86_64.whl (48.6MB)\n",
            "\u001b[K     |████████████████████████████████| 48.6MB 115kB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from plantcv) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from plantcv) (1.19.5)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.7/dist-packages (from plantcv) (2.12.0)\n",
            "Requirement already satisfied: matplotlib>=1.5 in /usr/local/lib/python3.7/dist-packages (from plantcv) (3.2.2)\n",
            "Collecting distributed>=2.19\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/f8/ac2c18adde6477bca3881c4d3cfa74c7f4da7ee82f3c83c201aa3b9ca5ee/distributed-2021.4.1-py3-none-any.whl (696kB)\n",
            "\u001b[K     |████████████████████████████████| 706kB 40.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->plantcv) (2018.9)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->plantcv) (1.1.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->plantcv) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->plantcv) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->plantcv) (2.5.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->plantcv) (1.0.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from plotnine->plantcv) (0.10.2)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from plotnine->plantcv) (0.5.1)\n",
            "Requirement already satisfied: descartes>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from plotnine->plantcv) (1.1.0)\n",
            "Requirement already satisfied: mizani>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from plotnine->plantcv) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->plantcv) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->plantcv) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->plantcv) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->plantcv) (1.3.1)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.19->dask-jobqueue->plantcv) (0.11.1)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.19->dask-jobqueue->plantcv) (2.0.0)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.19->dask-jobqueue->plantcv) (7.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed>=2.19->dask-jobqueue->plantcv) (56.0.0)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.19->dask-jobqueue->plantcv) (5.4.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from distributed>=2.19->dask-jobqueue->plantcv) (3.13)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.19->dask-jobqueue->plantcv) (1.0.2)\n",
            "Collecting cloudpickle>=1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/e3/898487e5dbeb612054cf2e0c188463acb358167fef749c53c8bb8918cea1/cloudpickle-1.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.19->dask-jobqueue->plantcv) (2.3.0)\n",
            "Requirement already satisfied: tornado>=5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from distributed>=2.19->dask-jobqueue->plantcv) (5.1.1)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.19->dask-jobqueue->plantcv) (1.7.0)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image->plantcv) (4.4.2)\n",
            "Requirement already satisfied: palettable in /usr/local/lib/python3.7/dist-packages (from mizani>=0.6.0->plotnine->plantcv) (3.3.0)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.19->dask-jobqueue->plantcv) (1.0.1)\n",
            "\u001b[31mERROR: distributed 2021.4.1 has requirement dask>=2021.03.0, but you'll have dask 2.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: dask-jobqueue 0.7.2 has requirement dask>=2.19, but you'll have dask 2.12.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: cloudpickle, distributed, dask-jobqueue, opencv-python, plantcv\n",
            "  Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "Successfully installed cloudpickle-1.6.0 dask-jobqueue-0.7.2 distributed-2021.4.1 opencv-python-3.4.13.47 plantcv-3.12.0\n",
            "Collecting c3d\n",
            "  Downloading https://files.pythonhosted.org/packages/80/39/1fddfb01d5f142b2ec1c199c78eaca1094f053af66235c76ba4d14fc7950/c3d-0.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from c3d) (1.19.5)\n",
            "Installing collected packages: c3d\n",
            "Successfully installed c3d-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gnveOQLzZs-"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import c3d\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "import os\n",
        "from plantcv import plantcv as pcv\n",
        "from scipy import ndimage\n",
        "import torchvision"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCAC2zBMNOjE",
        "outputId": "b5a90acb-1807-4e77-af95-248c28975dbf"
      },
      "source": [
        "## Mount Google Drive Data (If using Google Colaboratory)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "except:\n",
        "    print(\"Mounting Failed.\")\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prEI4BySN1tM"
      },
      "source": [
        "data_dir = \"/content/gdrive/MyDrive/BerkeleyMHAD/\"\n",
        "subjects = ['S01', 'S02', 'S03', 'S04', 'S05','S06', 'S07', 'S08', 'S09', 'S10', 'S11', 'S12']\n",
        "actions = ['A01', 'A02', 'A03', 'A04', 'A05','A06', 'A07', 'A08', 'A09', 'A10', 'A11']\n",
        "reps = ['R01', 'R02', 'R03', 'R04', 'R05']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPQyI2ZUbV7Z"
      },
      "source": [
        "#LSTM on Skeleton Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSGM-xw4cj4_"
      },
      "source": [
        "################ Dataloader for Berkeley Mocap Optical Data #################\n",
        "\n",
        "def c3d2array(loc: str, frame_rate):\n",
        "    \"\"\"\n",
        "    Takes in the file location of the c3d file as a string and returns a \n",
        "    numpy array w/ the sensor data\n",
        "    Array Shape: Num_frames x 43 x 3 \n",
        "      43 corresponds to the number of nodes on the person\n",
        "      3 corresponds to spatial coordinates of the nodes\n",
        "    \"\"\"\n",
        "    point_series = []\n",
        "    reader = c3d.Reader(open(loc, 'rb'))\n",
        "    for i, points, analog in reader.read_frames():     \n",
        "        if i % frame_rate == 0: ## Set Frame Rate to approximately 22 Hz instead of 480 Hz\n",
        "            point_series.append(points[:, 0:3])\n",
        "    point_series = np.array(point_series)\n",
        "    return point_series\n",
        "\n",
        "class BerkeleyMocapOpticalDataset(Dataset):\n",
        "    \"\"\"Berkeley Mocap Optical Dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, train, frame_rate, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (string): Directory with all the data\n",
        "            train (string): has to be one of \"train\", \"test\", or \"val\"\n",
        "            frame_rate (integer): In Hz \n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        if train == 'train':\n",
        "            self.list_c3d = [file for file in os.listdir(root_dir) if (os.path.isfile(os.path.join(root_dir, file)) and file[-1] != 't' and int(file[5:7]) < 9) ] #list of all the c3d file names for the first 8 subjects\n",
        "        elif train == 'test':\n",
        "            self.list_c3d = [file for file in os.listdir(root_dir) if (os.path.isfile(os.path.join(root_dir, file)) and file[-1] != 't' and int(file[5:7]) > 8 and int(file[5:7]) < 12) ] #list of all the c3d file names for the subjects 9, 10, 11\n",
        "        else:\n",
        "            self.list_c3d = [file for file in os.listdir(root_dir) if (os.path.isfile(os.path.join(root_dir, file)) and file[-1] != 't' and int(file[5:7]) == 12) ] #list of all the c3d file names for the subject 12\n",
        "        self.frame_rate = frame_rate\n",
        "        self.transform = transform\n",
        "        for idx, item in enumerate(self.list_c3d): \n",
        "            item_loc = os.path.join(self.root_dir, item)\n",
        "            self.list_c3d[idx] = (c3d2array(item_loc, self.frame_rate), item)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.list_c3d)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        sample = self.list_c3d[idx][0]\n",
        "        c3d_file_location = os.path.join(self.root_dir,\n",
        "                                self.list_c3d[idx][1])\n",
        "        label_location = c3d_file_location.find('_a')\n",
        "        if label_location == -1: # FUCK T-POSE\n",
        "            label = 12\n",
        "        else: \n",
        "            label = int(c3d_file_location[label_location+2:label_location+4])\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "        # Flatten Samples \n",
        "        sample = torch.transpose(sample, 0, 1)\n",
        "        sample = torch.flatten(sample, 1, 2)\n",
        "        sample = torch.unsqueeze(sample, 0)\n",
        "        sample = sample.float()\n",
        "        # I think labels should go from 0 through 11 since we are using argmax later for loss/accuracy\n",
        "        return sample, label - 1\n",
        "\n",
        "\n",
        "############### Compute Mean and SD across the dataset #############\n",
        "## If you wish to uncomment the code below and rerun it, you might have to comment out the three lines which cflatten the sample in the class above\n",
        "'''transform = None\n",
        "root_dir = data_dir + 'Mocap/OpticalData'\n",
        "frame_rate = 1\n",
        "\n",
        "dataloader = BerkeleyMocapOpticalDataset(root_dir, \"train\", 1)\n",
        "x_list = []\n",
        "y_list = []\n",
        "z_list = []\n",
        "\n",
        "for sample,_ in dataloader:\n",
        "  x_list.append(np.ndarray.flatten(sample[:,:,0]))\n",
        "  y_list.append(np.ndarray.flatten(sample[:,:,1]))\n",
        "  z_list.append(np.ndarray.flatten(sample[:,:,2]))\n",
        "\n",
        "x_list = np.concatenate(np.array(x_list))\n",
        "y_list = np.concatenate(np.array(y_list))\n",
        "z_list = np.concatenate(np.array(z_list))\n",
        "x_mean = np.mean(x_list)\n",
        "x_sd = np.std(x_list)\n",
        "y_mean = np.mean(y_list)\n",
        "y_sd = np.std(y_list)\n",
        "z_mean = np.mean(z_list)\n",
        "z_sd = np.std(z_list)\n",
        "print([x_mean, y_mean, z_mean, x_sd, y_sd, z_sd])'''\n",
        "\n",
        "############### Define a transform with mean, std, and tensor ############\n",
        "## So we don't need to rerun for the mean and standard deviations every time\n",
        "x_mean, x_sd, y_mean, y_sd, z_mean, z_sd = -455.09898495222086, 245.84348947768748, 148.47916727630624, 183.09031602408763, 814.4396506806088, 538.2824468734605\n",
        "transform = torchvision.transforms.Compose([\n",
        "  torchvision.transforms.ToTensor(),\n",
        "  torchvision.transforms.Normalize((x_mean, y_mean, z_mean), (x_sd, y_sd, z_sd)),\n",
        "])\n",
        "\n",
        "\n",
        "############# Final Dataloaders ####################\n",
        "root_dir = data_dir + 'Mocap/OpticalData'\n",
        "frame_rate = 22\n",
        "val_dataloader = BerkeleyMocapOpticalDataset(root_dir, \"val\", frame_rate, transform=transform)\n",
        "train_dataloader = BerkeleyMocapOpticalDataset(root_dir, \"train\", frame_rate, transform=transform)\n",
        "test_dataloader = BerkeleyMocapOpticalDataset(root_dir, \"test\", frame_rate, transform=transform)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ehz48DvAcqVk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        },
        "outputId": "6ea44734-cb93-4fb8-bc8e-c08450cae3ee"
      },
      "source": [
        "############ Test The Dataloader ######################\n",
        "\n",
        "## This code is for case in which the sample is NOT flattened\n",
        "'''i = 3\n",
        "for sample,_ in train_dataloader:\n",
        "  if i == 0:\n",
        "    break\n",
        "  i = i - 1\n",
        "  frame = 1\n",
        "  xs, ys, zs = sample[0, frame, :], sample[1, frame, :], sample[2, frame, :]\n",
        "  plt.figure()\n",
        "  plt.scatter(xs, zs)\n",
        "  plt.axis('scaled')\n",
        "  xs, ys, zs = sample[0, frame+10, :], sample[1, frame+10, :], sample[2, frame+10, :]\n",
        "  plt.scatter(xs, zs)\n",
        "  plt.axis('scaled')'''\n",
        "\n",
        "## This code is for the case in which the sample IS flattened\n",
        "i = 3\n",
        "for sample,_ in train_dataloader:\n",
        "  if i == 0:\n",
        "    break\n",
        "  i = i - 1\n",
        "  frame = 1\n",
        "  xs, ys, zs = sample[0, frame, 0:43], sample[0, frame, 43:86], sample[0, frame, 86:]\n",
        "  plt.figure()\n",
        "  plt.scatter(xs, zs)\n",
        "  plt.axis('scaled')\n",
        "  xs, ys, zs = sample[0, frame+10, 0:43], sample[0, frame+10, 43:86], sample[0, frame+10, 86:]\n",
        "  plt.scatter(xs, zs)\n",
        "  plt.axis('scaled')"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNccTDNGxYdG"
      },
      "source": [
        "class skeletonLSTM(nn.Module):\n",
        "    def __init__(self, classes):\n",
        "        super(skeletonLSTM, self).__init__()\n",
        "        self.n_hidden = 100\n",
        "        self.n_layers = 2\n",
        "        self.l_lstm = torch.nn.LSTM(input_size = 129, \n",
        "                                 hidden_size = self.n_hidden,\n",
        "                                 num_layers = self.n_layers, \n",
        "                                 batch_first = True)\n",
        "        self.fc1 = nn.Linear(100, 50)\n",
        "        self.fc2 = nn.Linear(50, classes)\n",
        "        self.relu = nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        #intialize lstm hidden state\n",
        "        hidden_state = torch.zeros(self.n_layers, 1, self.n_hidden).cuda()\n",
        "        cell_state = torch.zeros(self.n_layers, 1, self.n_hidden).cuda()\n",
        "        self.hidden = (hidden_state, cell_state)      \n",
        "        #print(x.shape)\n",
        "        lstm_out, _ = self.l_lstm(x, self.hidden) #lstm_out shape is batch_size, seq len, hidden state\n",
        "        lstm_out = lstm_out[:,-1,:]\n",
        "        lstm_out = self.relu(self.fc1(lstm_out.squeeze()))\n",
        "        lstm_out = self.fc2(lstm_out)\n",
        "        return lstm_out\n",
        "    "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NugZGhITcZXP"
      },
      "source": [
        "class skeletonLSTMunrolled(nn.Module):\n",
        "    def __init__(self, classes):\n",
        "        super(skeletonLSTMunrolled, self).__init__()\n",
        "        self.n_hidden = 100\n",
        "        self.n_layers = 1\n",
        "        self.l_lstm = torch.nn.LSTM(input_size = 129, \n",
        "                                 hidden_size = self.n_hidden,\n",
        "                                 num_layers = self.n_layers, \n",
        "                                 batch_first = True)\n",
        "        self.fc1 = nn.Linear(100, 50)\n",
        "        self.fc2 = nn.Linear(50, classes)\n",
        "        self.relu = nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        #intialize lstm hidden state\n",
        "        hidden_state = torch.zeros(self.n_layers, 1, self.n_hidden).cuda()\n",
        "        cell_state = torch.zeros(self.n_layers, 1, self.n_hidden).cuda()\n",
        "        self.hidden = (hidden_state, cell_state)      \n",
        "        for frame in range(x.shape[1]):\n",
        "            x_frame = x[:, frame, :].unsqueeze(1)\n",
        "            x_frame, self.hidden = self.l_lstm(x_frame, self.hidden)#lstm_out shape is batch_size, seq len, hidden state\n",
        "        lstm_out = x_frame[:,-1,:]\n",
        "        lstm_out = self.relu(self.fc1(lstm_out.squeeze()))\n",
        "        lstm_out = self.fc2(lstm_out)\n",
        "        return lstm_out\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYYtqLfyyC0Z"
      },
      "source": [
        " num_epochs = 50\n",
        " num_classes = 11\n",
        " model = skeletonLSTM(num_classes)\n",
        " model.cuda()\n",
        " loss_func = nn.CrossEntropyLoss()\n",
        " optimizer = torch.optim.Adam(model.parameters())\n",
        " \n",
        " train_loss_vec = []\n",
        " val_loss_vec = []\n",
        " for epoch in range(num_epochs):\n",
        "    train_loss_for_epoch = []\n",
        "    val_loss_for_epoch = []\n",
        "    ########################### Training #####################################\n",
        "    print(\"\\nEPOCH \" +str(epoch+1)+\" of \"+str(num_epochs)+\"\\n\")\n",
        "    for inputs, labels in train_dataloader:\n",
        "          inputs = inputs.cuda()\n",
        "          model.train()\n",
        "          if labels not in tuple(range(num_classes)): #FUCK T-POSE\n",
        "              continue\n",
        "          labels = torch.Tensor([labels]).cuda()\n",
        "          predictions = model(inputs).unsqueeze(0)\n",
        "          loss = loss_func(predictions, labels.long())\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          train_loss_for_epoch.append(loss.item())\n",
        "\n",
        "    train_loss_vec.append(sum(train_loss_for_epoch) / len(train_loss_for_epoch))\n",
        "    for inputs, labels in val_dataloader:\n",
        "          inputs = inputs.cuda()\n",
        "          model.eval()\n",
        "          if labels not in tuple(range(num_classes)): #FUCK T-POSE\n",
        "              continue\n",
        "          labels = torch.Tensor([labels]).cuda()\n",
        "          predictions = model(inputs).unsqueeze(0)\n",
        "          loss = loss_func(predictions, labels.long())\n",
        "          val_loss_for_epoch.append(loss.item())\n",
        "          if val_loss_for_epoch[-1] == min(val_loss_for_epoch):\n",
        "              torch.save(model, '/content/gdrive/MyDrive/best_model.pth')\n",
        "    val_loss_vec.append(sum(val_loss_for_epoch) / len(val_loss_for_epoch) )\n",
        "    print(\"The training loss for Epoch \" + str(epoch + 1) + \" is \" + str(train_loss_vec[-1]))\n",
        "    print(\"The validation loss for Epoch \" + str(epoch + 1) + \" is \" + str(val_loss_vec[-1]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3XgAZ_FoXe1",
        "outputId": "0bc61be0-c2dd-450f-9db6-360a0e2ffd66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "num_epochs = 50\n",
        "num_classes = 11\n",
        "model = skeletonLSTMunrolled(num_classes)\n",
        "model.cuda()\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        " \n",
        "train_loss_vec = []\n",
        "val_loss_vec = []\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss_for_epoch = []\n",
        "    val_loss_for_epoch = []\n",
        "    ########################### Training #####################################\n",
        "    print(\"\\nEPOCH \" +str(epoch+1)+\" of \"+str(num_epochs)+\"\\n\")\n",
        "    for inputs, labels in train_dataloader:\n",
        "          inputs = inputs.cuda()\n",
        "          model.train()\n",
        "          if labels not in tuple(range(num_classes)): #FUCK T-POSE\n",
        "              continue\n",
        "          labels = torch.Tensor([labels]).cuda()\n",
        "          predictions = model(inputs).unsqueeze(0)\n",
        "          loss = loss_func(predictions, labels.long())\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          train_loss_for_epoch.append(loss.item())\n",
        "\n",
        "    train_loss_vec.append(sum(train_loss_for_epoch) / len(train_loss_for_epoch))\n",
        "    for inputs, labels in val_dataloader:\n",
        "          inputs = inputs.cuda()\n",
        "          model.eval()\n",
        "          if labels not in tuple(range(num_classes)): #FUCK T-POSE\n",
        "              continue\n",
        "          labels = torch.Tensor([labels]).cuda()\n",
        "          predictions = model(inputs).unsqueeze(0)\n",
        "          loss = loss_func(predictions, labels.long())\n",
        "          val_loss_for_epoch.append(loss.item())\n",
        "          if val_loss_for_epoch[-1] == min(val_loss_for_epoch):\n",
        "              torch.save(model, '/content/gdrive/MyDrive/best_model_unrolled.pth')\n",
        "    val_loss_vec.append(sum(val_loss_for_epoch) / len(val_loss_for_epoch) )\n",
        "    print(\"The training loss for Epoch \" + str(epoch + 1) + \" is \" + str(train_loss_vec[-1]))\n",
        "    print(\"The validation loss for Epoch \" + str(epoch + 1) + \" is \" + str(val_loss_vec[-1]))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "EPOCH 1 of 20\n",
            "\n",
            "The training loss for Epoch 1 is 1.1312232255935668\n",
            "The validation loss for Epoch 1 is 1.0949738025665283\n",
            "\n",
            "EPOCH 2 of 20\n",
            "\n",
            "The training loss for Epoch 2 is 1.098706163962682\n",
            "The validation loss for Epoch 2 is 1.0979700167973836\n",
            "\n",
            "EPOCH 3 of 20\n",
            "\n",
            "The training loss for Epoch 3 is 1.0909621740380924\n",
            "The validation loss for Epoch 3 is 1.1655609289805093\n",
            "\n",
            "EPOCH 4 of 20\n",
            "\n",
            "The training loss for Epoch 4 is 1.0470146780212721\n",
            "The validation loss for Epoch 4 is 1.0773457725842794\n",
            "\n",
            "EPOCH 5 of 20\n",
            "\n",
            "The training loss for Epoch 5 is 1.0108056947588921\n",
            "The validation loss for Epoch 5 is 0.9888019998868306\n",
            "\n",
            "EPOCH 6 of 20\n",
            "\n",
            "The training loss for Epoch 6 is 0.8072237047056358\n",
            "The validation loss for Epoch 6 is 0.5607468619942665\n",
            "\n",
            "EPOCH 7 of 20\n",
            "\n",
            "The training loss for Epoch 7 is 0.6030974195261175\n",
            "The validation loss for Epoch 7 is 0.5149517325063546\n",
            "\n",
            "EPOCH 8 of 20\n",
            "\n",
            "The training loss for Epoch 8 is 0.4630229561356828\n",
            "The validation loss for Epoch 8 is 0.39489944571008284\n",
            "\n",
            "EPOCH 9 of 20\n",
            "\n",
            "The training loss for Epoch 9 is 0.32814686046913266\n",
            "The validation loss for Epoch 9 is 0.3122238631360233\n",
            "\n",
            "EPOCH 10 of 20\n",
            "\n",
            "The training loss for Epoch 10 is 0.27857531869861607\n",
            "The validation loss for Epoch 10 is 0.34395562298595905\n",
            "\n",
            "EPOCH 11 of 20\n",
            "\n",
            "The training loss for Epoch 11 is 0.149257594300434\n",
            "The validation loss for Epoch 11 is 0.2245532043122997\n",
            "\n",
            "EPOCH 12 of 20\n",
            "\n",
            "The training loss for Epoch 12 is 0.036598397442139684\n",
            "The validation loss for Epoch 12 is 0.16964492300370088\n",
            "\n",
            "EPOCH 13 of 20\n",
            "\n",
            "The training loss for Epoch 13 is 0.018881351477466522\n",
            "The validation loss for Epoch 13 is 0.15748266194326183\n",
            "\n",
            "EPOCH 14 of 20\n",
            "\n",
            "The training loss for Epoch 14 is 0.01027837295793385\n",
            "The validation loss for Epoch 14 is 0.12286441441780577\n",
            "\n",
            "EPOCH 15 of 20\n",
            "\n",
            "The training loss for Epoch 15 is 0.005274906085105613\n",
            "The validation loss for Epoch 15 is 0.10801700527857368\n",
            "\n",
            "EPOCH 16 of 20\n",
            "\n",
            "The training loss for Epoch 16 is 0.0030880137712908135\n",
            "The validation loss for Epoch 16 is 0.09457161582928772\n",
            "\n",
            "EPOCH 17 of 20\n",
            "\n",
            "The training loss for Epoch 17 is 0.0018694928038409367\n",
            "The validation loss for Epoch 17 is 0.09483821572600087\n",
            "\n",
            "EPOCH 18 of 20\n",
            "\n",
            "The training loss for Epoch 18 is 0.0012942173753496414\n",
            "The validation loss for Epoch 18 is 0.0959396661821908\n",
            "\n",
            "EPOCH 19 of 20\n",
            "\n",
            "The training loss for Epoch 19 is 0.0009780885834819249\n",
            "The validation loss for Epoch 19 is 0.09752387143040929\n",
            "\n",
            "EPOCH 20 of 20\n",
            "\n",
            "The training loss for Epoch 20 is 0.0007599208412405763\n",
            "The validation loss for Epoch 20 is 0.09906013157354512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M57LENMrdCL-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a09c419-f140-49a1-aa07-1cc845fdd884"
      },
      "source": [
        "def train_val_test(model, num_classes=11):\n",
        "    ################ Model Accuracy On Train Dataset Post Training #################\n",
        "    accurates = 0\n",
        "    samples = 0 \n",
        "    for input, label in train_dataloader:\n",
        "        if label not in tuple(range(num_classes)): #FUCK T-POSE\n",
        "            continue\n",
        "        input = input.cuda()\n",
        "        out = model(input)\n",
        "        if torch.argmax(out).item() == label:\n",
        "          accurates += 1\n",
        "        samples += 1\n",
        "    accuracy = accurates / samples\n",
        "    print('The model accuracy on the train dataset after training is ' + str(accuracy))\n",
        "\n",
        "    ################ Model Accuracy On Validation Dataset Post Training #################\n",
        "    accurates = 0\n",
        "    samples = 0 \n",
        "    for input, label in val_dataloader:\n",
        "        if label not in tuple(range(num_classes)): #FUCK T-POSE\n",
        "            continue\n",
        "        input = input.cuda()\n",
        "        out = model(input)\n",
        "        if torch.argmax(out).item() == label:\n",
        "          accurates += 1\n",
        "        samples += 1\n",
        "    accuracy = accurates / samples\n",
        "    print('The model accuracy on the validation dataset after training is ' + str(accuracy))\n",
        "\n",
        "    # Accuracies are 98/96/82\n",
        "    ################ Model Accuracy On Test Dataset Post Training #################\n",
        "    accurates = 0\n",
        "    samples = 0 \n",
        "    for input, label in test_dataloader:\n",
        "        if label not in tuple(range(num_classes)): #FUCK T-POSE\n",
        "            continue\n",
        "        input = input.cuda()\n",
        "        out = model(input)\n",
        "        if torch.argmax(out).item() == label:\n",
        "          accurates += 1\n",
        "        samples += 1\n",
        "    accuracy = accurates / samples\n",
        "    print('The model accuracy on the testing dataset after training is ' + str(accuracy))\n",
        "\n",
        "\n",
        "model = torch.load('/content/gdrive/MyDrive/best_model.pth')\n",
        "# 45ish epoch model https://drive.google.com/file/d/1SzOCnZ5kWuuEQ5GpYz9TAqYbjwYfP5kZ/view?usp=sharing\n",
        "    ################ Model Accuracy On Train Dataset Post Training #################\n",
        "train_val_test(model, 11)    "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model accuracy on the train dataset after training is 1.0\n",
            "The model accuracy on the validation dataset after training is 0.9818181818181818\n",
            "The model accuracy on the testing dataset after training is 0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDkblanyqu8H",
        "outputId": "7cd7f141-8f62-4b09-d527-206dcb415fef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = torch.load('/content/gdrive/MyDrive/best_model_unrolled.pth')\n",
        "# 45ish epoch model https://drive.google.com/file/d/1SzOCnZ5kWuuEQ5GpYz9TAqYbjwYfP5kZ/view?usp=sharing\n",
        "    ################ Model Accuracy On Train Dataset Post Training #################\n",
        "train_val_test(model, 3)    "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model accuracy on the train dataset after training is 1.0\n",
            "The model accuracy on the validation dataset after training is 0.9333333333333333\n",
            "The model accuracy on the testing dataset after training is 0.6666666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZhSlQumNxup",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "b2b49f6c-995e-4d4e-a3a7-dd0431ef85de"
      },
      "source": [
        "plt.plot(train_loss_vec)\n",
        "plt.plot(val_loss_vec)\n",
        "plt.xlabel('Epochs'), plt.ylabel('Cross Entropy Loss')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-41df40ff43f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cross Entropy Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loss_vec' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EVi7IUF9EEU"
      },
      "source": [
        "\n",
        "model = torch.load('/content/gdrive/MyDrive/best_model.pth')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJOXCF4V-jZ1"
      },
      "source": [
        "\n",
        "class GradientAttack():\n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        def __init__(self, loss, epsilon):\n",
        "            \"\"\"\n",
        "            \n",
        "            \"\"\"\n",
        "            self.loss = loss\n",
        "            self.epsilon = epsilon\n",
        "\n",
        "        def forward(self, x, y, model, num_iter=1, alpha=0.01):\n",
        "            \"\"\"\n",
        "            Generates an adversary using the gradient sign method\n",
        "            given an input feature, its associated label, and the model\n",
        "            x: feature vector\n",
        "            y: label associated with the feature vector\n",
        "            model: the model used to classify x\n",
        "            num_iter: number of iterations to perturb sample, for num_iter=1, uses fast gradient sign method\n",
        "            alpha: the size of the perturbation for iterative gradient sign method         \n",
        "            \"\"\"\n",
        "            y = torch.Tensor([y]).cuda()\n",
        "            x = x.cuda()\n",
        "            model.train()\n",
        "            x_adv = x\n",
        "            for iteration in range(num_iter):\n",
        "                x_adv = x_adv.cuda()\n",
        "                x_adv = Variable(x_adv, requires_grad=True)\n",
        "                # Step 1: Calculate the Loss and then calculate the\n",
        "                # gradient of the Loss w.r.t the image\n",
        "                loss_adv = self.loss(model(x_adv).unsqueeze(0), y.long())\n",
        "                loss_adv.backward(retain_graph=True) \n",
        "                with torch.no_grad():\n",
        "                    # Step 2: Add the gradient (or its sign for each pixel),\n",
        "                    # multiplied by a small step size, to the original image                   \n",
        "                    # You might need to clamp the modified image to \n",
        "                    # make sure the values of each pixel are between [0,1]    \n",
        "                    if num_iter > 1:                                                           \n",
        "                        x_temp = x_adv + torch.sign(x_adv.grad) * alpha\n",
        "                        # Clamp the attack to be within such that the maximum difference is epsilon\n",
        "                        x_adv = x + torch.clamp(x_temp - x, -self.epsilon, self.epsilon)\n",
        "                    else:\n",
        "                        x_adv = x + torch.sign(x_adv.grad) * self.epsilon\n",
        "            return x_adv"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8IR9qQLRo6I"
      },
      "source": [
        "def printgradnorm(self, grad_input, grad_output):\n",
        "\n",
        "    print('Inside ' + self.__class__.__name__ + ' backward')\n",
        "    print('Inside class:' + self.__class__.__name__)\n",
        "    print('')\n",
        "    print('grad_input: ', type(grad_input))\n",
        "    print('grad_input[0]: ', type(grad_input[0]))\n",
        "    print('grad_output: ', type(grad_output))\n",
        "    print('grad_output[0]: ', type(grad_output[0]))\n",
        "    print('')\n",
        "    print('grad_input size:', grad_input[0].size())\n",
        "    print('grad_output size:', grad_output[0].size())\n",
        "    print('grad_input norm:', grad_input[0].norm())\n",
        "\n",
        "class PMPAttack():\n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        def __init__(self, loss, epsilon):\n",
        "            \"\"\"\n",
        "            \n",
        "            \"\"\"\n",
        "            self.loss = loss\n",
        "            self.epsilon = epsilon\n",
        "\n",
        "        def forward(self, x, y, model, num_iter=1, alpha=0.01):\n",
        "            \"\"\"\n",
        "            Generates an adversary using the gradient sign method\n",
        "            given an input feature, its associated label, and the model\n",
        "            x: feature vector\n",
        "            y: label associated with the feature vector\n",
        "            model: the model used to classify x\n",
        "            num_iter: number of iterations to perturb sample, for num_iter=1, uses fast gradient sign method\n",
        "            alpha: the size of the perturbation for iterative gradient sign method         \n",
        "            \"\"\"\n",
        "            y = torch.Tensor([y]).cuda()\n",
        "            x = x.cuda()\n",
        "            model.train()\n",
        "            x_adv = x\n",
        "            ## Step 1\n",
        "            ## for debugging purposes, hidden state jacobian should be 100 x 100\n",
        "\n",
        "            x_adv = x_adv.cuda()\n",
        "            x_adv = Variable(x_adv, requires_grad=True)\n",
        "            loss_adv = self.loss(model(x_adv).unsqueeze(0), y.long())\n",
        "            loss_adv.backward(retain_graph=True) \n",
        "            for k in range(x_adv.shape[1]):\n",
        "                print(model.l_lstm.weight_hh_l0)\n",
        "            for iteration in range(num_iter):\n",
        "                x_adv = x_adv.cuda()\n",
        "                x_adv = Variable(x_adv, requires_grad=True)\n",
        "                # Step 1: Calculate the Loss and then calculate the\n",
        "                # gradient of the Loss w.r.t the image\n",
        "                loss_adv = self.loss(model(x_adv).unsqueeze(0), y.long())\n",
        "                loss_adv.backward(retain_graph=True) \n",
        "                with torch.no_grad():\n",
        "                    # Step 2: Add the gradient (or its sign for each pixel),\n",
        "                    # multiplied by a small step size, to the original image                   \n",
        "                    # You might need to clamp the modified image to \n",
        "                    # make sure the values of each pixel are between [0,1]    \n",
        "                    if num_iter > 1:                                                           \n",
        "                        x_temp = x_adv + torch.sign(x_adv.grad) * alpha\n",
        "                        # Clamp the attack to be within such that the maximum difference is epsilon\n",
        "                        x_adv = x + torch.clamp(x_temp - x, -self.epsilon, self.epsilon)\n",
        "                    else:\n",
        "                        x_adv = x + torch.sign(x_adv.grad) * self.epsilon\n",
        "            return x_adv"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0MVArlvR1hF",
        "outputId": "909790cf-9517-406c-f329-013ad968bd25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "adv_attack = PMPAttack(loss, 0.1)\n",
        "\n",
        "model = torch.load('/content/gdrive/MyDrive/best_model.pth')\n",
        "print(model)\n",
        "for input, label in train_dataloader:\n",
        "    if label == 11: \n",
        "        continue\n",
        "    input_adv = adv_attack.forward(input, label, model, num_iter=1, alpha=.01)\n",
        "    model.eval()\n",
        "    out = model(input_adv)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "skeletonLSTM(\n",
            "  (l_lstm): LSTM(129, 100, num_layers=2, batch_first=True)\n",
            "  (fc1): Linear(in_features=100, out_features=50, bias=True)\n",
            "  (fc2): Linear(in_features=50, out_features=11, bias=True)\n",
            "  (relu): ReLU()\n",
            ")\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0504, -0.0220,  0.0409,  ..., -0.0248, -0.0078,  0.1165],\n",
            "        [-0.0903,  0.0112,  0.0518,  ...,  0.0324, -0.0639, -0.1527],\n",
            "        [-0.2247,  0.0874,  0.1159,  ...,  0.2170, -0.0356, -0.1312],\n",
            "        ...,\n",
            "        [-0.0308, -0.1572,  0.0246,  ..., -0.0934,  0.0238, -0.0540],\n",
            "        [ 0.2093, -0.1201,  0.0281,  ...,  0.0153, -0.0664, -0.1955],\n",
            "        [-0.0698, -0.0937,  0.0607,  ...,  0.0512,  0.0884,  0.0592]],\n",
            "       device='cuda:0', requires_grad=True)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-a36c10dc0fc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0minput_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madv_attack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_adv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-7c73c173b09e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y, model, num_iter, alpha)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mloss_adv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_adv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_hh_l0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mx_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_adv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_full_backward_hook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_twM4HZVeLC",
        "outputId": "d810fec2-ff26-4a58-9bde-d58156c3f684"
      },
      "source": [
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "adv_attack = GradientAttack(loss, 0.1)\n",
        "\n",
        "################ Model Accuracy On Train Dataset Against Attacks#################\n",
        "accurates = 0\n",
        "for input, label in train_dataloader:\n",
        "    if label == 11: \n",
        "        continue\n",
        "    input_adv = adv_attack.forward(input, label, model, num_iter=1)\n",
        "    model.eval()\n",
        "    out = model(input_adv)\n",
        "    if torch.argmax(out).item() == label:\n",
        "        accurates += 1\n",
        "\n",
        "accuracy = accurates / len(train_dataloader)\n",
        "print('The model accuracy on the train dataset after training is ' + str(accuracy))\n",
        "\n",
        "################ Model Accuracy On Validation Dataset Against Attacks #################\n",
        "accurates = 0\n",
        "for input, label in val_dataloader:\n",
        "    if label == 11: \n",
        "        continue\n",
        "    input_adv = adv_attack.forward(input, label, model, num_iter=1)\n",
        "    model.eval()\n",
        "    out = model(input_adv)\n",
        "    if torch.argmax(out).item() == label:\n",
        "        accurates += 1\n",
        "\n",
        "accuracy = accurates / len(val_dataloader)\n",
        "print('The model accuracy on the validation dataset after training is ' + str(accuracy))\n",
        "\n",
        "################ Model Accuracy On Test Dataset Against Attacks#################    \n",
        "accurates = 0\n",
        "for input, label in test_dataloader:\n",
        "    if label == 11: \n",
        "        continue\n",
        "    input_adv = adv_attack.forward(input, label, model, num_iter=1)\n",
        "    model.eval()\n",
        "    out = model(input_adv)\n",
        "    if torch.argmax(out).item() == label:\n",
        "        accurates += 1\n",
        "\n",
        "accuracy = accurates / len(test_dataloader)\n",
        "print('The model accuracy on the testing dataset after training is ' + str(accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model accuracy on the train dataset after training is 0.8568232662192393\n",
            "The model accuracy on the validation dataset after training is 0.7678571428571429\n",
            "The model accuracy on the testing dataset after training is 0.6190476190476191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmbTnlI-d9Jo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b103a47e-6d99-415c-95a5-23b83628c65c"
      },
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "adv_attack = GradientAttack(loss, 0.1)\n",
        "\n",
        "################ Model Accuracy On Train Dataset Against Attacks#################\n",
        "accurates = 0\n",
        "for input, label in train_dataloader:\n",
        "    if label == 11: \n",
        "      continue\n",
        "    input_adv = adv_attack.forward(input, label, model, num_iter=100, alpha=0.005)\n",
        "    model.eval()\n",
        "    out = model(input_adv)\n",
        "    if torch.argmax(out).item() == label:\n",
        "      accurates += 1\n",
        "\n",
        "accuracy = accurates / len(train_dataloader)\n",
        "print('The model accuracy on the train dataset after training is ' + str(accuracy))\n",
        "\n",
        "################ Model Accuracy On Validation Dataset Against Attacks#################\n",
        "accurates = 0\n",
        "for input, label in val_dataloader:\n",
        "    if label == 11: \n",
        "          continue\n",
        "    input_adv = adv_attack.forward(input, label, model, num_iter=100, alpha=0.005)\n",
        "    model.eval()\n",
        "    out = model(input_adv)\n",
        "    if torch.argmax(out).item() == label:\n",
        "      accurates += 1\n",
        "\n",
        "accuracy = accurates / len(val_dataloader)\n",
        "print('The model accuracy on the validation dataset after training is ' + str(accuracy))\n",
        "\n",
        "\n",
        "################ Model Accuracy On Test Dataset Against Attacks#################\n",
        "accurates = 0\n",
        "for input, label in test_dataloader:\n",
        "    if label == 11: \n",
        "          continue\n",
        "    input_adv = adv_attack.forward(input, label, model, num_iter=100, alpha=0.005)\n",
        "    model.eval()\n",
        "    out = model(input_adv)\n",
        "    if torch.argmax(out).item() == label:\n",
        "      accurates += 1\n",
        "\n",
        "accuracy = accurates / len(test_dataloader)\n",
        "print('The model accuracy on the testing dataset after training is ' + str(accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model accuracy on the train dataset after training is 0.6666666666666666\n",
            "The model accuracy on the validation dataset after training is 0.6607142857142857\n",
            "The model accuracy on the testing dataset after training is 0.5416666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhCllQ4n_Ctl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761
        },
        "outputId": "0db3e681-ca08-42e9-dd5e-9d03243ebd1f"
      },
      "source": [
        "## This code is for the case in which the sample IS flattened\n",
        "i = 3\n",
        "for input, label in train_dataloader:\n",
        "  if label == 11: \n",
        "      continue\n",
        "  orig_input = input\n",
        "  sample = adv_attack.forward(input, label, model, num_iter=200, alpha=0.0025).cpu().detach()\n",
        "  if i == 0:\n",
        "    break\n",
        "  i = i - 1\n",
        "  frame = 1\n",
        "  xs, ys, zs = sample[0, frame, 0:43], sample[0, frame, 43:86], sample[0, frame, 86:]\n",
        "  plt.figure()\n",
        "  plt.scatter(xs, zs)\n",
        "  plt.axis('scaled')\n",
        "  xs, ys, zs = orig_input[0, frame, 0:43], orig_input[0, frame, 43:86], orig_input[0, frame, 86:]\n",
        "  plt.scatter(xs, zs)\n",
        "  plt.axis('scaled')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR0AAAD4CAYAAADRlDL+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZrklEQVR4nO3dfZBV9X3H8feXddE1OqwKibJAsK1Da4SEujGxZtq0mKoZQULiVtOmsU1KpxOHJnZssCaEMp1KdCZOaZwmVDPqtNHspIgYSaliOtY0Dy4+gEiYEsfEXUwFdUmt2/D07R/3Lty9nHP23nvOPfc8fF4zzO6ee/aec+5yvuf39P39zN0REUnLlE6fgIiUi4KOiKRKQUdEUqWgIyKpUtARkVSd1OkTiDJ9+nSfO3dup09DRJq0bdu2/e4+I+i1TAeduXPnMjQ01OnTEJEmmdlPwl5T9UpEUqWgIyKpSiTomNnXzOwVM3su5PX3m9kBM3um+m9VEscVkfxJqk3nbuDLwL0R+/yHu1+Z0PFEJKcSKem4++PAa0m8l4gUW5ptOheb2bNm9m0ze0fYTma23MyGzGxo3759KZ5ewWwfhNsvgNW9la/bBzt9RiJAekHnKeDt7v5O4O+BjWE7uvt6d+939/4ZMwK7+WUy2wfhoRVw4CXAK18fWqHAI5mQStBx95+7+xvV7zcD3WY2PY1jl9LWNXBobOK2Q2OV7SIdlkrQMbOzzcyq319UPe6raRy7lA4MN7ddJEWJ9F6Z2X3A+4HpZjYMfAHoBnD3rwAfAf7MzA4DY8A1rtnD2mfarGrVKmC7SIclEnTc/dpJXv8ylS512T5YqeYcGK4EgUWrYMFAssdYtKrShlNbxeruqWwX6bBM514VzngD73gwGG/ghWQDz/h7tTu4ibRAQSdNUQ28SQeEBQOh77nx6RFu27KbvaNjzOzt4cbL5rF0YV+yxxcJoaCTpgw08G58eoSbNuxg7NARAEZGx7hpww6AiYEnjWqglJISPtMU1pCbYgPvbVt2Hws448YOHeG2LbuPb9A4H2kjBZ00LVpVadCtlXID797Rscm3a5yPtJGqV20Q2maSgQbemb09jAQEnpm9NcEwA9VAKS4FnYRN2mYS0cCbhhsvmzfh/AB6uru48bJ5x3fSOB9pI1WvEtZQm0kHLV3Yxy3L5tPX24MBfb093LJs/sRG5AxUA6W4VNJJWENtJh22dGFfdBd5RDVQ3e0Sl4JOwhpqM8mDgGpgw93tIhFUvUrYjZfNo6e7a8K2E9pMcirrVUfJB5V0Ejb+xC9iFSQPVUfJPgWdNpi0zSSnClN1lI5S9UoaVuSqo6RHJR1pWJGrjpIeBR1pSlGrjpIeVa9EJFUKOiKSKgUdEUmVgo6IpEpBR0RSpaAjIqlS0BGRVCUSdMzsa2b2ipk9F/K6mdk6M9tjZtvN7NeTOK6I5E9SJZ27gcsjXr8COK/6bznwDwkdV0RyJpGg4+6PA69F7HIVcK9XfB/oNbNzkji2iORLWm06fUDtpLvD1W0nMLPlZjZkZkP79u1L5eREJD2Za0h29/Xu3u/u/TNmzOj06YhIwtIKOiPA7JqfZ1W35cf2Qbj9AljdW/mqhedEWpJW0NkE/GG1F+u9wAF3fzmlY8enFS+TpQBeaolMbWFm9wHvB6ab2TDwBaAbwN2/AmwGPgjsAd4E/iiJ46YmasVLre/dnPEAPv55jgdw0GdZEokEHXe/dpLXHfhUEsfqCK14mRwF8NLLXENyJoWtbKkVL5unAF56CjqN0IqXyVEALz0FnUYsGIDF62DabMAqXxevU3WgFQrgpac5khsVsOLlOC2124SIJYulHBR0YtJSu8EiA3FEAJfiU/UqJi21e6LxQDwyOoZzPBBvfDpf40GlPRR0YtJSuydSIJYoCjoxhS2pW+aldhWIJUoxg06Kw+wzs9RuhlILUg/EGbp2mVzxgk7KeVJLF/Zxy7L59PX2YEBfbw+3LJufbiPyt26ADcszkxuWaiBWXlzuWCVDIZv6+/t9aGiouV+6/YLqf8A602bDZwJnU8237YOVgEPA37GD15zaMIKy/b1zwsy2uXt/0GvF6zIv2zD7rWsIDDjQ0WtObc3zsv29C6B41auyDbOPurmKes21yvb3LoDiBZ2yDbMPvbmsuNdcq2x/7wIoXvUqYph9IdMVFq2aOD8NAAb9f1zca641SVpF4a8/h4rXkByiPl0BKj0qqfc0tcP2wdAgW9hrbkDZr7+TytWQHCJqlGxe/gOGPrVDcpmKcM1xlP36s6o0QSfvo2RbSSzN+zXHVfbrz6riNSSHyHu6Qiv5THm/5rjKfv1ZVZqgk5l0hRa18tTO+zXHVfbrz6rSVK/GqyB57cmY2dvDSECAiXpq5/2a4yr79WdVaXqv8k49MZIn6r0qAD21pSgUdHIktXwmkTZKpCHZzC43s91mtsfMVga8fp2Z7TOzZ6r/PpnEcUUkf2KXdMysC7gD+AAwDDxpZpvc/fm6Xb/h7tfHPZ6I5FsSJZ2LgD3u/oK7HwTuB65K4H1FpICSCDp9QO0sSsPVbfU+bGbbzeybZjY77M3MbLmZDZnZ0L59+xI4vRLQdJ2SI2kNDnwImOvuC4BHgHvCdnT39e7e7+79M2bMaPwIZb3xNF2n5EwSQWcEqC25zKpuO8bdX3X3X1R/vBO4MIHjHlfmG2/rmrppLaj8vOFPyhV865X1IZQDSQSdJ4HzzOxcM5sKXANsqt3BzM6p+XEJsCuB4x4XduNtXZPoYTIpaubAMgXfWmV+COVA7KDj7oeB64EtVILJoLvvNLM1ZrakutsKM9tpZs8CK4Dr4h53gjLPkzvZtJxlCb61yvwQyoFEBge6+2Zgc922VTXf3wTclMSxAk2bFbIiQAnmyQ2cObBOGYJvrTI/hHKgGFnmZZ4nd8EALF5XWXIlxPDRs7hk7WPlWUtck7VnWjGCzoQbzypfF68LnE2vkBYMVNZ4WvaPJwTfN30qtx4eODbpVykCT5kfQjlQnNyrkCk7oZiTcwdf0/FJyo8eGGbv0bO49fAAm46+DyjeVJ2R07dC6GTt0lnFCTohWpnmM+uir6kSfH955cOBS/AVZarOSf+uEQ8h6axiVK8itDLNZ9Y1ck1Fn6qziH/Xsih80Cni5NyNXFMiU3VmeIBdEf+uZVH4oJO5J34CN3Ij17R0YR+3LJtPX28PBvT19jQ3y2DGB9hl7u8qDStmm07N4nOP9JzNqqkf5psHf+PYyx2bnHv8Rh4fUzN+I0NT7Q83XjYvcOrS+muKNelX1AC7DLSVNPoZSPYUr6RT94Q+dexl1nbfyXWn/bC1J36SEhopG7sU04iMD7Br6jPIcDWxjIo3MfvtF4SMTp5dGcvSSat7IbBPyWD1aNpnEy3Ln2Mz6kuXUBmzU6ZxXB0QNTF78Uo6WX5C95wRvD2LI2WLMsBOeViZU7w2nazmYW0fhINvnLh9Snc2b+RJBtjlZsBllh9CJVW8oBOUAJmFJ/TWNXDk4InbTz49u8X8kAF2uRpwmdWHUIkVr3qV1TyssCfr2OtA5Ua+ZO1jnLvy4cwnZ+ZqYF5RqokFUrySDmQzDyviiZurkgM5G5inPKzMKWbQCdHRmzui2nfb5vCSQxaDTivrqrdb5MNEeViZUrzqVYSOVgsiqn25KjmQUIpFgsYfJiOjYziUaxqPHCpVSafjN3fIE3daTzejY4cCt2dR1tZVj3qYZLGkWHalCjpZrBYAmDW3PQuytK56xx8m0pRSVa+yVi0YN/rmiaWcqO25kkIKgpI/86VUQSexnKWEb6TC3jQpZapn9WEiwUpVvYIEqgUJZYrXKmzGdEqZ6llrY5JoxUv4bLewREjrAj/a8jiQ3KQVNCNPCa6SqKiEz0RKOmZ2OfB3QBdwp7uvrXv9ZOBeKssJvwr8nru/mMSxUxc2stirpZQWSz5ZaphNjFIQJEDsNh0z6wLuAK4AzgeuNbPz63b7BPC6u/8KcDvwxbjH7ZhGbhhlMVcEpCAc7jqF1f/74Vyke0h7JNGQfBGwx91fcPeDwP3AVXX7XAXcU/3+m8Ais+x0CDeV9xSUyxNEWcwnDIh8s+ccVh76JHe/cZEG8ZVYEtWrPqC2DD0MvCdsH3c/bGYHgLOA/fVvZmbLgeUAc+bMSeD0KsLaTJpOjajP5bEpx6tWNX7GdL7/9EjxqkwBGk1B+MDaxxg5OLFhWYP4yidzvVfuvh5YD5WG5IZ+qWZO5KCG3KjA0tJo1tqRxQEz073pU/nbQ1fzSIaTNpPSTNBOahBfIRvdSySJoDMC1C6kPau6LWifYTM7CZhGpUE5vpAu7CdffJ1PP38ee0fHmGLGkbpeuvHAEjRCGZq4EarB52cb/oq3+n72es2qmkeL/xRvJmgnMSJ80iA3yQNIOi+JoPMkcJ6ZnUsluFwDfLRun03Ax4HvAR8BHvOk+upDxoLM3HYrI79YB3BCwBk3MjqGEdyp29TAvAUDXPz1twS+z8joGOeufLiwT+RmSi9JjEcKC3KrN+1kadd3Ex9DJcmL3ZDs7oeB64EtwC5g0N13mtkaM1tS3e0u4Cwz2wPcAKyMe9xjQhpsz2mgINVlFjaKpOmBeVFBqsiNps2Mpp50RHgDI73Dgtzo2CH2brhJ8yHnQCJtOu6+Gdhct21Vzff/B1ydxLFOEDIWZK+fFflrPd1dJzwxxzlMvBEaKK4HPcXrFbHRtNnSS+h4pAZHeodV0QDO9v2VJ0Y99SRmSv5zrwK6sI8CfbafJ6auYMmUJ45t7zKb8ITtC3lKH9veRO5Q/VM8TNEynxPLZ2tw1YaoEuhenx78ggYjZkrmeq+aNqEL+yXAmIKDwSzbz9ruO+EQbDr6Pk4/5SRWL3nHhBsi8indZO5Q7VP8krWPZXIajXZIZDR1g6s2LF3Yx18/tJPXAzLwtx59Fx+zR5lSG/U1H3Lm5L+kA5UA8JnnqoPQJrbSnGoH+cJJ9/LE1BU8dfRq3r3xN3ly01eBBp7SMZYvUeZzk8JKIwHbv7D4HXR3TSxPLpnyBFd3PT4x4GDwzo+qETlj8l3SqW9vCcrzAc60NzCrrDnVx37OfOrzMPcMWDAQ/ZSOkTukzOcmNbt0UF0PwF+eNMipVr/Ej8POB+DKLyV6qhJPfrPMg5aLDe0AD9DI8rhakjZdDTbaB1VdXzj5o3WlnBo9Z8IVX9TfLEVtzzLviKD2Fpz6wOMeMu1nIz0aWr4kXQ2u2hDUGL/XpzPLTsiqqRh7TeN1MiS/bTqhQcMnJBi+zunBuzXaozHeXrR6tPJV/2k7Lqgx/tbDA9FlXI3XyYz8Bp3QhsfZx4LEqZ/9ET++8POMcfLEfdSjkWtBjfSPdP0WB7t7o39R43UyIb9Bp8HlYt+95E/pWfbl7C0zLC0L63U8efFt0dOOaLxOJuS3TaeZ9hat8Fg4wb2O1b/xtz9baceppdJtZuS390okirLNO6qYvVciUVS6zaz8tumISC4p6IhIqhR0RCRVCjoikio1JEsmafL14lLQkcxpelkgyRVVryRzolaYkPxTSSdBqhIkI6n1sSSbVNJJyHiVYGR0rNCrP6ShmRUmJH8UdBKiKkFyNNVrsal6lRBVCVoUkCO1dGElfUFV1WKKFXTM7EzgG8Bc4EVgwN1fD9jvCLCj+uNP3X1J/T55l8SSuaUTsdbV0oUDCjIFFbd6tRLY6u7nAVsJX7lzzN3fVf1XuIADqhK0pMG1rqRY4gadq4B7qt/fAyyN+X65ldiic2USY4kfya+4bTpvc/eXq9//DHhbyH6nmNkQcBhY6+4bw97QzJYDywHmzJkT8/TaJGSulkQWnSuTGEv8SH5NGnTM7FHg7ICXbq79wd3dzMJmBHu7u4+Y2S8Bj5nZDnf/cdCO7r4eWA+VSbwmO7/UNbjmtjSg2bWupBAmDTrufmnYa2b232Z2jru/bGbnAK+EvMdI9esLZvbvwEIgMOhkXpNLDUsELfFTSnGrV5uAjwNrq18frN/BzM4A3nT3X5jZdOAS4NaYx+0ctUMkSzP8lU7chuS1wAfM7L+AS6s/Y2b9ZnZndZ9fA4bM7FngO1TadJ6PedzOaWLNbRE5UaySjru/CiwK2D4EfLL6/X8C8+McJ1PUDiESi9IgmrVgoLJultbREmmJ0iBaoXYIkZYp6EjmaIqQYlPQaRPdOK3RrIHFpzadNtDcOq3TFCHFp6DTBrpxWqcpQopPQacNdOO0TrMGFp+CThvoxmmdpggpPgWdNtCN0zpNEVJ86r2KI2KKC9B0m5FCPjtAU4QUnIJOqyaZ4kI3TgRND1Jqql61SlNttk6fXakp6LRKU1y0Tp9dqSnotEpTXLROn12pKei0atGqypQWtTTFRWP02ZWagk6rNMVF6/TZlZq5Z2/u83H9/f0+NDTU6dMQkSaZ2TZ37w96TSUdEUmVgo6IpEpBR0RSpaAjIqlS0BGRVCnoiEiqYgUdM7vazHaa2VEzC+weq+53uZntNrM9ZrYyzjFFJN/ilnSeA5YBj4ftYGZdwB3AFcD5wLVmdn7M44pITsVd4XMXgJlF7XYRsMfdX6juez9wFZDfpYVFpGVptOn0AS/V/Dxc3RbIzJab2ZCZDe3bt6/tJyci6Zq0pGNmjwJnB7x0s7s/mPQJuft6YD1U0iCSfn8R6axJg467XxrzGCPA7JqfZ1W3iUgJpVG9ehI4z8zONbOpwDXAphSOKyIZFLfL/ENmNgxcDDxsZluq22ea2WYAdz8MXA9sAXYBg+6+M95pi0hexe29egB4IGD7XuCDNT9vBjbHOZaIFINWg2iDjU+PaPkZkRAKOgnb+PQIN23YcWwt85HRMW7asANAgUcE5V4l7rYtu48FnHFjh45w25bdHTojkWxR0EnY3tGxpraLlI2CTsJm9vY0tV2kbBR0EnbjZfPo6e6asK2nu4sbL5vXoTMSyRY1JCdsvLFYvVcRtg9WlhA+MFxZYG/RKi0/UyIKOnGE3DxLF/YpyITZPggPrTi+lvmBlyo/gwJPSah61arxm+fAS4Afv3m2D3b6zLJt65rjAWfcobHKdikFBZ1W6eZpzYHh5rZL4SjotEo3T2umzWpuuxSOgk6rdPO0ZtEq6K4bPtDdU9kupaCg0yrdPK1ZMACL18G02YBVvi5ep0bkElHvVavGbxJ1/UYKTn4dgAUDx1/7+hgzNz/Gb//qDL7zo30aalBw5p7dGUH7+/t9aGio06fRstobrvfUbtzhwNih0txQ9cmvUBkoecuy+QAnvFZvfN+if05FZGbb3D1wWSqVdNqk/oZ7/c1Dx14rS+b5ZMmvUQGndt8if0ZlpDadNgm64WqVIfM8Kvm10QRYJcoWj4JOmzRysxT9hopKfm00AVaJssWjoNMmjdwsRb+hopJfg16rp0TZYlLQaZPJbqoy3FBLF/Zxy7L59PX2YEBfb8+xhuGlXd9l22mf5oVTfp8npq7gutN+yB+8d07gvlIs6r2KKyJjuuy9VxPUfk49Z8DBN+DIweOvd/dovE6BRPVeKejEUZ8xDYABXhn0pnE7FYGfU4Bps+Ezz6VzTtJWUUFH1as4gpI+qQZxZZ0fF/g5BVDeWinEXWzvajPbaWZHzSwwqlX3e9HMdpjZM2aW4aJLkya7SZR1XtFoMFHeWinEHRz4HLAM+GoD+/62u++PebxsmTarOp9OBD29G/uclLfWed+6AbbdDX4ErAsuvA6u/FLih4lV0nH3Xe5e7BFuUYKSPuvp6R38OU3php4zUdJnRnzrBhi6qxJwoPJ16K7K9oSllQbhwL+ZmQNfdff1KR23vSYkfb7EsUbkcXp6Vyg5Nvu23R2+PeHSzqRBx8weBc4OeOlmd3+wweO8z91HzOytwCNm9iN3fzzkeMuB5QBz5sxp8O07aMHA8ZtHE46Hq/2cJHs8JGUnbHsMkwYdd7807kHcfaT69RUzewC4CAgMOtVS0HqodJnHPXaqdGNJXllXcICx6FHjrWh7l7mZvcXMTh//HvhdKg3QIpIVF17X3PYY4naZf8jMhoGLgYfNbEt1+0wz21zd7W3AE2b2LPBD4GF3/9c4xxWRhF35Jej/xPGSjXVVfm5D75VGJItIpM9t3MF9P3iJI+50mXHte2bzN0vnR/6OJvESkZZ8buMO/un7Pz328xH3Yz9PFnjCKA1CRELd94PgQZ1h2xuhoCMioY6ENL+EbW+Ego6IhOoya2p7IxR0RCTUte+Z3dT2RqghWURCjTcWN9t7FUVd5iKSOE3iJSKZoaAjIqlS0BGRVCnoiEiqFHREJFWZ7r0ys33ATzp9HgGmA8Wa77l5Zf8Myn79EP0ZvN3dZwS9kOmgk1VmNhTWHVgWZf8Myn790PpnoOqViKRKQUdEUqWg05pirGYRT9k/g7JfP7T4GahNR0RSpZKOiKRKQUdEUqWg0yIzu9rMdprZUTMrTdepmV1uZrvNbI+Zrez0+aTNzL5mZq+YWSmXUTKz2Wb2HTN7vvr//8+bfQ8FndY9BywjZNHAIjKzLuAO4ArgfOBaMzu/s2eVuruByzt9Eh10GPgLdz8feC/wqWb/DyjotMjdd7n77k6fR8ouAva4+wvufhC4H7iqw+eUqupy2K91+jw6xd1fdvenqt//D7AL6GvmPRR0pBl9QO0yAMM0+R9OisPM5gILgR8083uarjSCmT0KnB3w0s3u/mDa5yOSFWZ2GvAvwKfd/efN/K6CTgR3v7TT55AxI0DtjNyzqtukRMysm0rA+Wd339Ds76t6Jc14EjjPzM41s6nANcCmDp+TpMjMDLgL2OXuLS10rqDTIjP7kJkNAxcDD5vZlk6fU7u5+2HgemALlQbEQXff2dmzSpeZ3Qd8D5hnZsNm9olOn1PKLgE+BvyOmT1T/ffBZt5AaRAikiqVdEQkVQo6IpIqBR0RSZWCjoikSkFHRFKloCMiqVLQEZFU/T/QCDGY2dhMDgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jM-wZF0EPr7c"
      },
      "source": [
        "Probably should use 20 or so epochs based on these results"
      ]
    }
  ]
}